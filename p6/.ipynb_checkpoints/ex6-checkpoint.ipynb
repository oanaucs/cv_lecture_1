{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsblatt 6: Hauptachsentransformation & Klassifikation\n",
    "Ziel dieser Übungsserie ist es, mit Hilfe von Python ein Objekterkennungssystem zu entwickeln und mit dem Leave-One-Out Verfahren zu bewerten. Das Vorgehen ist dabei in einzelne Schritte unterteilt, sodass die folgenden Aufgaben aufeinander aufbauen. __Lesen Sie die Aufgabenbeschreibungen aufmerksam!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1: Laden des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Moodle finden Sie den Datensatz `toy-dataset`, welcher vier Ordner mit $16\\times 16$ Pixel großen Beispielbildern der Klassen *apple*, *car*, *cow* und *dog* enthält.\n",
    "Im Folgenden soll ein Klassifikator angelernt werden, welcher diese vier Klassen erfolgreich unterscheiden kann.\n",
    "Laden Sie dazu zunächst den Datensatz.\n",
    "Der nachfolgend zu realisierende Klassifikator soll jeweils 9 von 10 Bildern je Klasse während der Lernphase erhalten.\n",
    "Das jeweils verbleibende Bild soll als *unbekanntes* Testbild verwendet werden.\n",
    "Erstellen Sie eine Routine, welches für einen übergebenen Datensatz eine zufällige Einteilung in Trainings- und Testdaten realisiert.\n",
    "Achten Sie insbesondere darauf, das Verhältnis zwischen Trainings- und Testdaten variabel zu gestalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Pfade, Pakete etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import sklearn.decomposition\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './toy-dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Laden des Datensatzes\n",
    "Definieren Sie eine Funktion `ex6_load_dataset`, die den Datesatz einliest. Laden Sie den Datensatz so, dass Sie jedem Bild eine Klasse zuordnen können! Denkbar ist z.B. ein Array von Tupeln `(Bild, Klasse)`. Achten Sie jeweils auf eine geeignete Repräsentation von Bildern und Klassen. Tipp: Verwenden Sie zunächst die Funktion `os.walk`, um die Verzeichnisstruktur abzubilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pgm(f):\n",
    "    header = f.readline()\n",
    "    size = [int(i) for i in f.readline().split()]\n",
    "    depth = int(f.readline())\n",
    "    image = []\n",
    "    for i in range(size[0]):\n",
    "        row = []\n",
    "        for j in range(size[1]):\n",
    "            row.append(ord(f.read(1)))\n",
    "        image.append(row)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex6_load_dataset(path):\n",
    "    data = {}\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for d in dirs:\n",
    "            data.update({d: []})\n",
    "        for name in files:            \n",
    "            f = open(os.path.join(root, name), 'rb')\n",
    "            image = read_pgm(f)\n",
    "            for d in data.keys():\n",
    "                if d in name:\n",
    "                    data[d].append(np.array(image) / np.max(image))\n",
    "    for key, values in data.items():\n",
    "        data[key] = np.array(data[key])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ex6_load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aufteilen des Datensatzes\n",
    "Definieren Sie nun eine Funktion `ex6_split_dataset`. Teilen Sie darin den Datensatz in Trainings- und Testbeispiele anhand des Verhältnisses `test_fraction` auf! Achten Sie dabei auf die identische Verteilung der Klassen in beiden Teilmengen. Erzwingen Sie mindestens ein Testbeispiel pro Klasse und geben Sie Trainings- und Testdaten getrennt zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex6_split_dataset(data, test_fraction):\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for key, values in data.items():\n",
    "        test_size = int(values.shape[0] * test_fraction)\n",
    "        train_size = values.shape[0] - test_size\n",
    "        \n",
    "        for i in range(0, train_size):\n",
    "            np.random.shuffle(data[key])\n",
    "            idx = np.random.randint(0, data[key].shape[0], 1)\n",
    "            training_data.append((data[key][idx], key))\n",
    "            data[key] = np.delete(data[key], idx, axis=0)\n",
    "            \n",
    "        for i in range(0, test_size):\n",
    "            np.random.shuffle(data[key])\n",
    "            idx = np.random.randint(0, data[key].shape[0], 1)\n",
    "            test_data.append((data[key][idx], key))\n",
    "            data[key] = np.delete(data[key], idx, axis=0)\n",
    "    \n",
    "    \n",
    "    return np.array(training_data), np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ex6_split_dataset(data, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2: Merkmalsextraktion\n",
    "Bevor ein Klassifikator trainiert werden kann, müssen Bilder geeignet durch Merkmale repräsentiert werden.\n",
    "\n",
    "1. Eine sehr einfache Möglichkeit, Merkmale aus den Bildern zu gewinnen besteht darin, die Pixelwerte der Bilder direkt als Merkmal zu wenden. In Fall einfacher Grauwertbilder wird dazu jedes Bild vektorisiert, indem die Pixelwerte zeilen- oder spaltenweise in einem Spalten-Vektor abgelegt (z.B. mit der `reshape`-Funktion aus dem Paket `numpy`). Für die Bilder aus obigem Datensatz ergibt dies eine Merkmalsdimension $d=256 \\times 1$.\n",
    "\n",
    "2. Häufig muss die Dimension der Merkmale reduziert werden, um eine schnellere Klassifikation mit geringerem Speicherbedarf zu ermöglichen. Dazu kann zum Beispiel eine Hauptachsentransformation durchgeführt werden (*principal component analysis*, PCA). In `scikit-learn` steht dafür die Funktion `sklearn.decomposition.PCA` zur Verfügung, die hier jedoch **nicht** verwendet werden soll. Stattdessen kann eine entsprechende Transformation auch wie folgt umgesetzt werden:\n",
    "\n",
    "    1. Erstellen Sie eine Datenmatrix $\\mathbf{X}\\in \\mathbb{R}^{d\\times n}$ in der spaltenweise die $n$ Merkmalsvektoren gelagert sind.\n",
    "    2. Machen sie jede Merkmalsdimension **mittelwertfrei**, d.h., subtrahieren Sie je Dimension den entsprechenden Mittelwert aller Trainingsdaten.\n",
    "    3. Berechnen Sie anschließend die Kovarianzmatrix $\\mathbf{\\Sigma} = \\mathbf{X}\\mathbf{X}^T $, mit $\\mathbf{\\Sigma}\\in \\mathbb{R}^{d\\times d}$\n",
    "    4. Berechnen Sie schließlich die Eigenwerte und -vektoren von $\\mathbf{\\Sigma}$ mittels geeigneter `numpy`-Funktionen (z.B. `np.linalg.eig`, `np.linalg.svd`, $\\dots$)\n",
    "\n",
    "Für eine Dimensionsreduktion auf die $k,~1\\le k\\le d,~$ *wichtigsten* Dimensionen werden die Eigenvektoren zu den $k$ größten Eigenwerten verwendet.\n",
    "Wir fassen diese Eigenvektoren in einer Matrix $\\mathbf{P} = [\\mathbf{v}_1,\\ldots,\\mathbf{v}_k]$ zusammen.\n",
    "Auf diese $k$ Eigenvektoren können nun alle ursprünglichen Merkmalsvektoren $\\mathbf{x_i}$ mittels $\\mathbf{\\hat{x_i}} = \\mathbf{P}^T\\mathbf{x_i}$ projiziert werden.\n",
    "\n",
    "\n",
    "Implementieren Sie beide Verfahren zur Beschreibung von Bildern.\n",
    "Achten Sie insbesondere darauf, die Pixelwerte für die Merkmalsvektoren auf den Wertebereich $[0,1]$ zu **skalieren**!\n",
    "Vergleichen Sie im Zweifelsfall Ihre Ergebnisse mit denen der entsprechenden Python-Routinen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pixelwerte als Merkmale\n",
    "Definieren Sie zunächst eine Funktion `ex6_feature_extraction_simple`, die Bilder in eine Merkmalsrepräsentation umwandelt. Die Funktion bekommt Trainings- und Testdaten als Liste von `(Bild, Klasse)`-Tupeln übergeben und gibt sie jeweils als Liste von `(Merkmalsvektor, Klasse)`-Tupeln zurück. Obwohl die Trennung zwischen Trainings- und Testdaten für diese Variante der Merkmalsextraktion nicht relevant ist, wollen wir eine einheitliche Schnittstelle schaffen, die in Aufgabe 4 wichtig wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex6_feature_extraction_simple(training_data, test_data):\n",
    "    training_features = []\n",
    "    test_features = []\n",
    "    \n",
    "    for sample in training_data:\n",
    "        training_features.append((np.array(sample[0]).flatten(), sample[1]))\n",
    "                                \n",
    "    for sample in test_data:\n",
    "        test_features.append((np.array(sample[0]).flatten(), sample[1]))\n",
    "    \n",
    "    return np.array(training_features), np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train, simple_test = ex6_feature_extraction_simple(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie jetzt die alternative Funktion `ex6_feature_extraction_pca`, die eine Hauptachsentransformation durchführt und analog zur vorherigen Funktion als Merkmale zurückgibt. Achten Sie darauf, nicht die Testdaten zur Ermittlung der Kovarianzmatrix zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex6_feature_extraction_pca(training_data, test_data, k=5):\n",
    "    training_data_matrix = []\n",
    "    train_labels = []\n",
    "    # matrix of shape n x p\n",
    "    for i in range(0, training_data.shape[0]):\n",
    "        feature_vec = np.array(training_data[i][0].flatten())\n",
    "        train_labels.append(training_data[i][1])\n",
    "        training_data_matrix.append(feature_vec)\n",
    "    training_data_matrix = np.array(training_data_matrix)\n",
    "    training_data_matrix = np.transpose(training_data_matrix)\n",
    "    \n",
    "    # mean of shape p x 1\n",
    "    mean = np.mean(training_data_matrix, axis=0)\n",
    "    training_data_matrix -= mean\n",
    "    \n",
    "    # cov matrix of shape p x p\n",
    "    cov_matrix = np.cov(training_data_matrix)\n",
    "    \n",
    "    # diagonal matrix eig_vec of shape p x p\n",
    "    eig_val, eig_vec = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    eig = list(zip(eig_val, eig_vec))\n",
    "    eig = sorted(eig,  key=lambda x: x[0])\n",
    "\n",
    "    # create matrix of shape p x k\n",
    "    a = []\n",
    "    for i in range(0, k):\n",
    "        a.append(eig[i][1])\n",
    "    a = np.transpose(np.array(a))\n",
    "        \n",
    "    # project training data\n",
    "    proj_train_features = np.transpose(np.dot(np.transpose(a), training_data_matrix))\n",
    "    train_features = []\n",
    "    for i in range(0, proj_train_features.shape[0]):\n",
    "        train_features.append((proj_train_features[i], train_labels[i]))\n",
    "    \n",
    "    test_data_matrix = []\n",
    "    test_labels = []\n",
    "    for i in range(0, test_data.shape[0]):\n",
    "        test_feature_vec = np.array(test_data[i][0].flatten())\n",
    "        test_data_matrix.append(test_feature_vec)\n",
    "        test_labels.append(test_data[i][1])\n",
    "    test_data_matrix = np.array(test_data_matrix)\n",
    "    test_data_matrix = np.transpose(test_data_matrix)\n",
    "    \n",
    "    test_features = []\n",
    "    proj_test_features = np.transpose(np.dot(np.transpose(a), test_data_matrix))\n",
    "    for i in range(0, proj_test_features.shape[0]):\n",
    "        test_features.append((proj_test_features[i], test_labels[i]))\n",
    "\n",
    "    return np.array(train_features), np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train, pca_test = ex6_feature_extraction_pca(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Nächster-Nachbar-Klassifikator\n",
    "Der vermutlich einfachste Klassifikator ist der Nächste-Nachbar-Klassifikator.\n",
    "Dieses Verfahren vergleicht den zu klassifizierenden Merkmalsvektor $\\mathbf{x}_*$ mit allen Merkmalsvektoren $\\mathbf{x}_i$ der Trainingsdaten.\n",
    "Die Klasse desjenigen Merkmalsvektors der Trainingsdaten, welches den geringsten Abstand zu $\\mathbf{x}_*$ aufweist, wird als Ergebnis der Klassifikation zurückgeliefert.\n",
    "\n",
    "Implementieren Sie diesen sogenannten Nächsten-Nachbar-Klassifikator.\n",
    "Achten Sie dabei darauf, dass er mit beliebigen Stichproben trainiert werden kann.\n",
    "\n",
    "Gestalten Sie die Distanzberechnung variabel. Welche Abstandsmaße sind Ihrer Meinung nach möglich bzw. sinnvoll?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Distanzberechnung\n",
    "Definieren Sie eine oder mehrere Distanzen als Funktion bzw. Lambda-Ausdruck, der einem Paar von Merkmalsvektoren `x` und `x_` eine skalare Distanz zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_euclid = lambda x, x_:np.sqrt(np.sum(np.power((x-x_), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Klassifikation\n",
    "Implementieren Sie nun eine Funktion `ex6_classify`, die als Eingabe ein Beispiel `x_star`, den Trainingsdatensatz sowie eine geeignete Distanzfunktion `d` bekommt. Der Rückgabewert soll die Klasse des nächstgelegenen Beispiels im Trainingsdatensatz sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex6_classify(x_star, training_features, d):\n",
    "    min_distance = 1000000.0\n",
    "    class_ = None\n",
    "    for i in range(0, training_features.shape[0]):\n",
    "        distance = d(training_features[i][0], x_star)\n",
    "        if distance < min_distance:\n",
    "            class_ = training_features[i][1]\n",
    "    \n",
    "    return class_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4: Leave-one-out Estimation\n",
    "Stellen Sie die vorherigen Teilaufgaben zu einem Gesamtsystem zusammen.\n",
    "Dabei soll aus den Eingabedaten aus jeder Klasse ein Bild ausgewählt werden, welches *nicht* für das „Lernen“ der Hauptachsentransformation und das Trainieren des Nächsten-Nachbar-Klassifikators verwendet wird (s. erste Aufgabe).\n",
    "Anschließend werden diese Bilder als Testdaten verwendet, transformiert und schließlich klassifiziert.\n",
    "Ermitteln Sie die Erkennungsleistung des Klassifikators.\n",
    "Variieren Sie nun das Verhältnis zwischen Anzahl der Trainings- und Testbeispiele.\n",
    "Was ist zu beobachten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst definieren wir einige Voreinstellungen für das Verfahren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.5\n",
    "d = d_euclid\n",
    "feature_extraction = ex6_feature_extraction_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden alle Schritte des Verfahrens nacheinander ausgeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = ex6_split_dataset(ex6_load_dataset(dataset_path), test_fraction)\n",
    "training_features, test_features = feature_extraction(training_data, test_data)\n",
    "test_predictions = [(ex6_classify(test_feature[0], training_features, d_euclid), test_feature[1]) for test_feature in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cow', 'apple'), ('cow', 'apple'), ('cow', 'apple'), ('cow', 'apple'), ('cow', 'apple'), ('cow', 'car'), ('cow', 'car'), ('cow', 'car'), ('cow', 'car'), ('cow', 'car'), ('cow', 'dog'), ('cow', 'dog'), ('cow', 'dog'), ('cow', 'dog'), ('cow', 'dog'), ('cow', 'cow'), ('cow', 'cow'), ('cow', 'cow'), ('cow', 'cow'), ('cow', 'cow')]\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun liegen in `test_predictions` Paare von vorhergesagten und tatsächlichen Klassen aller Testbeispiele. Überlegen Sie, welches Maß für die Genauigkeit der Vorhersage sinnvoll erscheint und implementieren Sie es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_learner(test_predictions):\n",
    "    n = len(test_predictions)\n",
    "    correct = 0\n",
    "    for i in range(0, n):\n",
    "        if (test_predictions[i][0] == test_predictions[i][1]):\n",
    "            correct += 1\n",
    "    return correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_learner(test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
